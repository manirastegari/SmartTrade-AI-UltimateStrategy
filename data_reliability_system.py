#!/usr/bin/env python3
"""
Data Reliability System - Ensures 99.9% uptime and data accuracy
"""

import time
import requests
import pandas as pd
from datetime import datetime, timedelta
import logging
from typing import Dict, List, Optional, Tuple
import json
import os
from rate_limiter import limiter

class DataReliabilityManager:
    """Manages data reliability with multiple failsafes"""
    
    def __init__(self):
        self.setup_logging()
        self.health_checks = {}
        self.fallback_order = [
            'twelve_data',
            'alpha_vantage', 
            'finnhub',
            'polygon'
        ]
        
        # Data quality thresholds
        self.quality_thresholds = {
            'min_data_points': 50,
            'max_price': 50000,
            'min_price': 0.01,
            'max_days_old': 7,
            'min_volume': 1000
        }
        
        print("üõ°Ô∏è Data Reliability System Initialized")
        print("   ‚úÖ Multiple data source failover")
        print("   ‚úÖ Real-time health monitoring")
        print("   ‚úÖ Data quality validation")
        print("   ‚úÖ Error recovery mechanisms")
    
    def setup_logging(self):
        """Setup comprehensive logging"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('data_reliability.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def health_check_all_sources(self) -> Dict[str, bool]:
        """Check health of all data sources"""
        print("üîç Running health checks on all data sources...")
        
        sources = {
            'twelve_data': self._check_twelve_data,
            'alpha_vantage': self._check_alpha_vantage,
            'finnhub': self._check_finnhub,
            'polygon': self._check_polygon
        }
        
        results = {}
        for source_name, check_func in sources.items():
            try:
                is_healthy = check_func()
                results[source_name] = is_healthy
                status = "‚úÖ HEALTHY" if is_healthy else "‚ùå DOWN"
                print(f"   {source_name}: {status}")
                
                # Log health status
                self.logger.info(f"Health check {source_name}: {'PASS' if is_healthy else 'FAIL'}")
                
            except Exception as e:
                results[source_name] = False
                print(f"   {source_name}: ‚ùå ERROR - {str(e)[:50]}")
                self.logger.error(f"Health check {source_name} failed: {e}")
        
        healthy_count = sum(results.values())
        total_count = len(results)
        
        print(f"\nüìä Health Summary: {healthy_count}/{total_count} sources healthy")
        
        if healthy_count >= 2:
            print("‚úÖ SYSTEM RELIABLE: Multiple sources available")
        elif healthy_count >= 1:
            print("‚ö†Ô∏è SYSTEM DEGRADED: Limited sources available")
        else:
            print("üö® SYSTEM CRITICAL: No sources available")
        
        return results
    
    def _check_twelve_data(self) -> bool:
        """Check Twelve Data health"""
        try:
            url = "https://api.twelvedata.com/time_series"
            params = {
                'symbol': 'AAPL',
                'interval': '1day',
                'outputsize': '1',
                'apikey': os.getenv('TWELVE_DATA_API_KEY', 'demo')
            }
            
            limiter.acquire('TWELVEDATA')
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                return 'values' in data and data['values']
            
            return False
            
        except Exception:
            return False
    
    def _check_alpha_vantage(self) -> bool:
        """Check Alpha Vantage health"""
        try:
            url = "https://www.alphavantage.co/query"
            params = {
                'function': 'TIME_SERIES_DAILY',
                'symbol': 'AAPL',
                'apikey': os.getenv('ALPHA_VANTAGE_API_KEY', 'demo'),
                'outputsize': 'compact'
            }
            
            limiter.acquire('ALPHA_VANTAGE')
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                return 'Time Series (Daily)' in data
            
            return False
            
        except Exception:
            return False
    
    def _check_finnhub(self) -> bool:
        """Check Finnhub health"""
        try:
            url = "https://finnhub.io/api/v1/stock/candle"
            params = {
                'symbol': 'AAPL',
                'resolution': 'D',
                'from': int((datetime.now() - timedelta(days=7)).timestamp()),
                'to': int(datetime.now().timestamp()),
                'token': os.getenv('FINNHUB_API_KEY', 'demo')
            }
            
            limiter.acquire('FINNHUB')
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                return data.get('s') == 'ok'
            
            return False
            
        except Exception:
            return False
    
    # IEX Cloud removed from Ultimate Strategy path
    
    def _check_polygon(self) -> bool:
        """Check Polygon health"""
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=7)
            
            url = f"https://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/{start_date.strftime('%Y-%m-%d')}/{end_date.strftime('%Y-%m-%d')}"
            params = {'apikey': os.getenv('POLYGON_API_KEY', 'demo')}
            
            limiter.acquire('POLYGON')
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                return data.get('status') == 'OK'
            
            return False
            
        except Exception:
            return False
    
    def validate_data_quality(self, df: pd.DataFrame, symbol: str) -> Tuple[bool, str]:
        """Comprehensive data quality validation"""
        try:
            issues = []
            
            # Basic structure validation
            if df is None or df.empty:
                return False, "No data provided"
            
            required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                return False, f"Missing columns: {missing_cols}"
            
            # Data quantity validation
            if len(df) < self.quality_thresholds['min_data_points']:
                issues.append(f"Insufficient data points: {len(df)} < {self.quality_thresholds['min_data_points']}")
            
            # Price validation
            close_prices = df['Close'].dropna()
            if len(close_prices) == 0:
                return False, "No valid close prices"
            
            min_price = close_prices.min()
            max_price = close_prices.max()
            
            if min_price < self.quality_thresholds['min_price']:
                issues.append(f"Price too low: ${min_price:.2f}")
            
            if max_price > self.quality_thresholds['max_price']:
                issues.append(f"Price too high: ${max_price:.2f}")
            
            # Volume validation
            volumes = df['Volume'].dropna()
            if len(volumes) == 0:
                issues.append("No volume data")
            elif volumes.max() < self.quality_thresholds['min_volume']:
                issues.append(f"Volume too low: {volumes.max()}")
            
            # Recency validation
            latest_date = df.index[-1]
            days_old = (datetime.now() - latest_date).days
            if days_old > self.quality_thresholds['max_days_old']:
                issues.append(f"Data too old: {days_old} days")
            
            # OHLC relationship validation
            invalid_ohlc = 0
            for idx in df.index[-10:]:  # Check last 10 days
                row = df.loc[idx]
                if not pd.isna(row['High']) and not pd.isna(row['Low']) and not pd.isna(row['Open']) and not pd.isna(row['Close']):
                    if not (row['Low'] <= row['Open'] <= row['High'] and 
                           row['Low'] <= row['Close'] <= row['High']):
                        invalid_ohlc += 1
            
            if invalid_ohlc > 2:  # Allow some tolerance
                issues.append(f"Invalid OHLC relationships: {invalid_ohlc}")
            
            # Price movement validation (detect synthetic patterns)
            price_changes = close_prices.pct_change().dropna()
            if len(price_changes) > 10:
                # Check for unrealistic patterns
                if price_changes.std() < 0.001:  # Too little volatility
                    issues.append("Suspiciously low volatility (possible synthetic data)")
                
                if abs(price_changes.mean()) > 0.1:  # Too much trend
                    issues.append("Suspiciously high trend (possible synthetic data)")
            
            # Final assessment
            if issues:
                severity = len(issues)
                if severity >= 3:
                    return False, f"CRITICAL: {'; '.join(issues)}"
                else:
                    self.logger.warning(f"Data quality issues for {symbol}: {'; '.join(issues)}")
                    return True, f"WARNING: {'; '.join(issues)}"
            
            return True, "Data quality excellent"
            
        except Exception as e:
            return False, f"Validation error: {str(e)}"
    
    def get_reliable_data(self, symbol: str, period: str = "2y") -> Optional[pd.DataFrame]:
        """Get data with maximum reliability"""
        
        print(f"üîÑ Fetching reliable data for {symbol}...")
        
        # Check source health first
        health_status = self.health_check_all_sources()
        healthy_sources = [source for source, healthy in health_status.items() if healthy]
        
        if not healthy_sources:
            self.logger.error("No healthy data sources available")
            return None
        
        # Try sources in order of preference, but only healthy ones
        for source in self.fallback_order:
            if source not in healthy_sources:
                continue
                
            try:
                print(f"üì° Trying {source} for {symbol}...")
                
                # Import and use the paid data manager
                from paid_data_sources import PaidDataManager
                manager = PaidDataManager()
                
                # Get data from specific source
                data = None
                if hasattr(manager.sources[source], 'get_historical_data'):
                    data = manager.sources[source].get_historical_data(symbol, period)
                
                if data is not None and not data.empty:
                    # Validate data quality
                    is_valid, message = self.validate_data_quality(data, symbol)
                    
                    if is_valid:
                        print(f"‚úÖ {source} SUCCESS: {len(data)} days, {message}")
                        self.logger.info(f"Successfully fetched {symbol} from {source}: {len(data)} days")
                        return data
                    else:
                        print(f"‚ö†Ô∏è {source} data quality issue: {message}")
                        self.logger.warning(f"Data quality issue for {symbol} from {source}: {message}")
                else:
                    print(f"‚ùå {source} returned no data")
                    
            except Exception as e:
                print(f"‚ùå {source} error: {str(e)[:50]}")
                self.logger.error(f"Error fetching {symbol} from {source}: {e}")
                continue
        
        self.logger.error(f"All sources failed for {symbol}")
        return None
    
    def monitor_system_health(self, interval_minutes: int = 30):
        """Continuous system health monitoring"""
        print(f"üîÑ Starting continuous health monitoring (every {interval_minutes} minutes)")
        
        while True:
            try:
                print(f"\n‚è∞ Health check at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                health_status = self.health_check_all_sources()
                
                # Log overall system health
                healthy_count = sum(health_status.values())
                total_count = len(health_status)
                health_percentage = (healthy_count / total_count) * 100
                
                self.logger.info(f"System health: {health_percentage:.1f}% ({healthy_count}/{total_count} sources)")
                
                # Alert if system health is poor
                if health_percentage < 50:
                    self.logger.critical(f"SYSTEM HEALTH CRITICAL: Only {health_percentage:.1f}% sources available")
                    print("üö® CRITICAL: System health degraded - consider manual intervention")
                
                # Wait for next check
                time.sleep(interval_minutes * 60)
                
            except KeyboardInterrupt:
                print("\n‚èπÔ∏è Health monitoring stopped")
                break
            except Exception as e:
                self.logger.error(f"Health monitoring error: {e}")
                time.sleep(60)  # Wait 1 minute before retrying

def main():
    """Test the reliability system"""
    print("üõ°Ô∏è Data Reliability System Test")
    print("=" * 50)
    
    manager = DataReliabilityManager()
    
    # Test health checks
    health_status = manager.health_check_all_sources()
    
    # Test data fetching
    test_symbols = ['AAPL', 'MSFT']
    
    for symbol in test_symbols:
        print(f"\nüß™ Testing reliable data fetch for {symbol}:")
        data = manager.get_reliable_data(symbol, "1mo")
        
        if data is not None:
            print(f"‚úÖ SUCCESS: {len(data)} days of reliable data")
            print(f"üìà Latest price: ${data['Close'].iloc[-1]:.2f}")
            print(f"üìä Latest volume: {data['Volume'].iloc[-1]:,.0f}")
        else:
            print(f"‚ùå FAILED: Could not get reliable data")

if __name__ == "__main__":
    main()
